{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1b8e71",
   "metadata": {},
   "source": [
    "# Custom Food Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3cb5b",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813c81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55901b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf57df",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c498d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## createing a small dataset with two attributes \n",
    "## name column consists of Food name\n",
    "## reviews column consists of the corresponding food review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e6cf0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"name\",\"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18008e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"name\"] = [\"rice\",\"chicken\",\"biriyani\",\"mashroom\",\"sandwich\",\"pizza\",\"burger\",\"daal\",\"fish\",\"kaachi\"]\n",
    "df[\"reviews\"] = [\"for healthy lunch rice is must\",\n",
    "                 \"chicken is my favourite food\",\n",
    "                 \"i love biriyani\",\n",
    "                 \"mashroom is a tasty food\",\n",
    "                 \"i prefer sandwich for breakfast\",\n",
    "                 \"pizza is my favourite\",\n",
    "                 \"i like burger\",\n",
    "                 \"daal is my weakness\",\n",
    "                 \"fish is a healthy item\",\n",
    "                 \"kaachi is one of my fav food\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b11b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rice</td>\n",
       "      <td>for healthy lunch rice is must</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chicken</td>\n",
       "      <td>chicken is my favourite food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biriyani</td>\n",
       "      <td>i love biriyani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mashroom</td>\n",
       "      <td>mashroom is a tasty food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sandwich</td>\n",
       "      <td>i prefer sandwich for breakfast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                          reviews\n",
       "0      rice   for healthy lunch rice is must\n",
       "1   chicken     chicken is my favourite food\n",
       "2  biriyani                  i love biriyani\n",
       "3  mashroom         mashroom is a tasty food\n",
       "4  sandwich  i prefer sandwich for breakfast"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f01b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pizza</td>\n",
       "      <td>pizza is my favourite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>burger</td>\n",
       "      <td>i like burger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daal</td>\n",
       "      <td>daal is my weakness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fish</td>\n",
       "      <td>fish is a healthy item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kaachi</td>\n",
       "      <td>kaachi is one of my fav food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                       reviews\n",
       "5   pizza         pizza is my favourite\n",
       "6  burger                 i like burger\n",
       "7    daal           daal is my weakness\n",
       "8    fish        fish is a healthy item\n",
       "9  kaachi  kaachi is one of my fav food"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b5db89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a89d51c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad00310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in /home/robin/.local/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in /home/robin/.local/lib/python3.8/site-packages (from wordcloud) (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/robin/.local/lib/python3.8/site-packages (from wordcloud) (1.22.3)\n",
      "Requirement already satisfied: matplotlib in /home/robin/.local/lib/python3.8/site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/robin/.local/lib/python3.8/site-packages (from matplotlib->wordcloud) (4.28.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/robin/.local/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/robin/.local/lib/python3.8/site-packages (from matplotlib->wordcloud) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/robin/.local/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/robin/.local/lib/python3.8/site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/robin/.local/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python3 -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a45d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7d210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER\n",
    "nlp0 = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b75ad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get All Components of this NLP Object\n",
    "nlp0.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d4c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner0 = nlp0.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbaf8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "ex1 = \"James went to London to buy Ibuprofen last year 2019\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94212138",
   "metadata": {},
   "outputs": [],
   "source": [
    "docx = nlp0(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d6bc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a377bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London GPE\n",
      "Ibuprofen ORG\n",
      "last year 2019 DATE\n"
     ]
    }
   ],
   "source": [
    "# Check for entities\n",
    "for entity in docx.ents:\n",
    "    print(entity,entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab05147",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = \"In spain at madrid i order sandwich for my breakfast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7768c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp0(ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa39e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spain GPE\n",
      "madrid GPE\n"
     ]
    }
   ],
   "source": [
    "for entity in doc2.ents:\n",
    "    print(entity,entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "041ffc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    processed_token = []\n",
    "    for token in review.split():\n",
    "        token = ''.join(e.lower() for e in token if e.isalnum())\n",
    "        processed_token.append(token)\n",
    "    return ' '.join(processed_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b923f42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rice',\n",
       " 'chicken',\n",
       " 'biriyani',\n",
       " 'mashroom',\n",
       " 'sandwich',\n",
       " 'pizza',\n",
       " 'burger',\n",
       " 'daal',\n",
       " 'fish',\n",
       " 'kaachi']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# food Names\n",
    "all_foods = df['name'].unique().tolist()\n",
    "\n",
    "all_foods = [x.lower() for x in all_foods]\n",
    "\n",
    "all_foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f80f81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     for healthy lunch rice is must\n",
       "1       chicken is my favourite food\n",
       "2                    i love biriyani\n",
       "3           mashroom is a tasty food\n",
       "4    i prefer sandwich for breakfast\n",
       "5              pizza is my favourite\n",
       "6                      i like burger\n",
       "7                daal is my weakness\n",
       "8             fish is a healthy item\n",
       "9       kaachi is one of my fav food\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d38aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                 rice\n",
      "reviews    for healthy lunch rice is must\n",
      "Name: 0, dtype: object\n",
      "name                            chicken\n",
      "reviews    chicken is my favourite food\n",
      "Name: 1, dtype: object\n",
      "name              biriyani\n",
      "reviews    i love biriyani\n",
      "Name: 2, dtype: object\n",
      "name                       mashroom\n",
      "reviews    mashroom is a tasty food\n",
      "Name: 3, dtype: object\n",
      "name                              sandwich\n",
      "reviews    i prefer sandwich for breakfast\n",
      "Name: 4, dtype: object\n",
      "name                       pizza\n",
      "reviews    pizza is my favourite\n",
      "Name: 5, dtype: object\n",
      "name              burger\n",
      "reviews    i like burger\n",
      "Name: 6, dtype: object\n",
      "name                      daal\n",
      "reviews    daal is my weakness\n",
      "Name: 7, dtype: object\n",
      "name                         fish\n",
      "reviews    fish is a healthy item\n",
      "Name: 8, dtype: object\n",
      "name                             kaachi\n",
      "reviews    kaachi is one of my fav food\n",
      "Name: 9, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i,name in df.iterrows():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f83fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##converting the training data into the spacy format data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5a7c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "TRAIN_DATA = []\n",
    "for _, item in df.iterrows():\n",
    "    ent_dict = {}\n",
    "    if count < 10:\n",
    "        review = process_review(item['reviews'])\n",
    "        #Locate foods and their positions once and add to the visited items.\n",
    "        visited_items = []\n",
    "        entities = []\n",
    "        for token in review.split():\n",
    "            if token in all_foods:\n",
    "                for i in re.finditer(token, review):\n",
    "                    if token not in visited_items:\n",
    "                        entity = (i.span()[0], i.span()[1], 'FOOD')\n",
    "                        visited_items.append(token)\n",
    "                        entities.append(entity)\n",
    "        if len(entities) > 0:\n",
    "            ent_dict['entities'] = entities\n",
    "            train_item = (review, ent_dict)\n",
    "            TRAIN_DATA.append(train_item)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acd90770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('for healthy lunch rice is must', {'entities': [(18, 22, 'FOOD')]}),\n",
       " ('chicken is my favourite food', {'entities': [(0, 7, 'FOOD')]}),\n",
       " ('i love biriyani', {'entities': [(7, 15, 'FOOD')]}),\n",
       " ('mashroom is a tasty food', {'entities': [(0, 8, 'FOOD')]}),\n",
       " ('i prefer sandwich for breakfast', {'entities': [(9, 17, 'FOOD')]}),\n",
       " ('pizza is my favourite', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('i like burger', {'entities': [(7, 13, 'FOOD')]}),\n",
       " ('daal is my weakness', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('fish is a healthy item', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('kaachi is one of my fav food', {'entities': [(0, 6, 'FOOD')]})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c0c83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a empty nlp model with English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e869901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96da329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2a10840",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 30\n",
    "\n",
    "def train_ner(training_data):\n",
    "    \n",
    "    \"\"\"Steps\n",
    "    Create a Blank NLP  model object\n",
    "    Create and add NER to the NLP model\n",
    "    Add Labels from your training data\n",
    "    Train  \n",
    "    \"\"\"\n",
    "    TRAIN_DATA = training_data\n",
    "    \n",
    "    # create blank Language class\n",
    "    nlp = spacy.blank(\"en\")  \n",
    "    print(\"Created blank 'en' model\")\n",
    "    \n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe('ner')\n",
    "    ner.add_label(\"label\")\n",
    "    \n",
    "#     if \"ner\" not in nlp.pipe_names:\n",
    "#         ner = nlp.add_pipe(\"ner\")\n",
    "#         #nlp.add_pipe(ner, last=True)\n",
    "#     # otherwise, get it so we can add labels\n",
    "#     else:\n",
    "#         ner = nlp.get_pipe(\"ner\")\n",
    "        \n",
    "        \n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        #for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        for batch in spacy.util.minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001)):\n",
    "            for text, annotations in batch:\n",
    "                # create Example\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                # Update the model\n",
    "                nlp.update([example], losses=losses, drop=0.5)\n",
    "\n",
    "#         batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "#         for batch in batches:\n",
    "#             texts, annotations = zip(*batch)\n",
    "#             example = []\n",
    "#             # Update the model with iterating each text\n",
    "#             for i in range(len(texts)):\n",
    "#                 doc = nlp.make_doc(texts[i])\n",
    "#                 example.append(Example.from_dict(doc, annotations[i]))\n",
    "        \n",
    "        print(\"Losses\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e9a0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Losses {'ner': 32.12554767727852}\n",
      "Losses {'ner': 20.396196506917477}\n",
      "Losses {'ner': 15.503781765699387}\n",
      "Losses {'ner': 12.066822669934481}\n",
      "Losses {'ner': 12.47229163285374}\n",
      "Losses {'ner': 7.940938097555772}\n",
      "Losses {'ner': 6.787303852563127}\n",
      "Losses {'ner': 5.859258757431729}\n",
      "Losses {'ner': 2.343737853891999}\n",
      "Losses {'ner': 2.320204331446069}\n",
      "Losses {'ner': 0.4368409196031431}\n",
      "Losses {'ner': 1.5692322826774254}\n",
      "Losses {'ner': 4.058147088082767}\n",
      "Losses {'ner': 0.0016758037000260265}\n",
      "Losses {'ner': 0.00015153878378842213}\n",
      "Losses {'ner': 1.8249410618941284}\n",
      "Losses {'ner': 0.0028785403970550873}\n",
      "Losses {'ner': 0.017999622452597244}\n",
      "Losses {'ner': 8.599518349506943e-06}\n",
      "Losses {'ner': 0.0029200013593541838}\n",
      "Losses {'ner': 0.01987721362405572}\n",
      "Losses {'ner': 8.641709652340436e-05}\n",
      "Losses {'ner': 0.0023726587143433663}\n",
      "Losses {'ner': 2.100480817475467e-08}\n",
      "Losses {'ner': 6.744607597911261e-05}\n",
      "Losses {'ner': 4.610307161968854e-06}\n",
      "Losses {'ner': 0.002055817556175286}\n",
      "Losses {'ner': 0.0024347788246063765}\n",
      "Losses {'ner': 2.0239216347608284}\n",
      "Losses {'ner': 0.12452665999765497}\n"
     ]
    }
   ],
   "source": [
    "# Let training the model\n",
    "\n",
    "nlp2 = train_ner(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dcad2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = \"i was in vacation at spain.i order sandwich for my breakfast and love to had rice with daal in lunch\"\n",
    "\n",
    "docx2 = nlp2(ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec271f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacation FOOD\n",
      "sandwich FOOD\n",
      "daal FOOD\n"
     ]
    }
   ],
   "source": [
    "for entity in docx2.ents:\n",
    "    print(entity,entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89c16869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(rice, 'FOOD')]\n",
      "[(biriyani, 'FOOD')]\n",
      "[(daal, 'FOOD')]\n",
      "[(mashroom, 'FOOD')]\n",
      "[(chicken, 'FOOD')]\n"
     ]
    }
   ],
   "source": [
    "for text,_ in TRAIN_DATA[:5]:\n",
    "    doc = nlp2(text)\n",
    "    result = [(ent,ent.label_) for ent in doc.ents]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eec02c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For another custom dataset with annotated format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2696a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Getting the ner component\n",
    "f_ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6ff5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New label to add\n",
    "LABEL = \"FOOD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ceba8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training examples in the required format\n",
    "\n",
    "TRAIN_FOOD_DATA =[ (\"Pizza is a common fast food.\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"Pasta is an italian recipe\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"China's noodles are very famous\", {\"entities\": [(8,14, \"FOOD\")]}),\n",
    "              (\"Shrimps are famous in China too\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Lasagna is another classic of Italy\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Sushi is extemely famous and expensive Japanese dish\", {\"entities\": [(0,5, \"FOOD\")]}),\n",
    "              (\"Unagi is a famous seafood of Japan\", {\"entities\": [(0,5, \"FOOD\")]}),\n",
    "              (\"Tempura , Soba are other famous dishes of Japan\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Udon is a healthy type of noodles\", {\"entities\": [(0,4, \"ORG\")]}),\n",
    "              (\"Chocolate soufflé is extremely famous french cuisine\", {\"entities\": [(0,17, \"FOOD\")]}),\n",
    "              (\"Flamiche is french pastry\", {\"entities\": [(0,8, \"FOOD\")]}),\n",
    "              (\"Burgers are the most commonly consumed fastfood\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Burgers are the most commonly consumed fastfood\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Frenchfries are considered too oily\", {\"entities\": [(0,11, \"FOOD\")]})\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "458cd4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the new label to ner\n",
    "f_ner.add_label(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ebafa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training\n",
    "\n",
    "optimizer = nlp.resume_training()\n",
    "move_names = list(f_ner.move_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61da308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pipes  want to train\n",
    "\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c60938c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pipes which should remain unaffected in training\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0878661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing requirements\n",
    "\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fe65b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses : {'ner': 18.603962196651075}\n",
      "losses : {'ner': 16.27411495364244}\n",
      "losses : {'ner': 15.04985213852342}\n",
      "losses : {'ner': 10.774062501142907}\n",
      "losses : {'ner': 5.8182633712076495}\n",
      "losses : {'ner': 1.478158594066599}\n",
      "losses : {'ner': 0.9667060405807044}\n",
      "losses : {'ner': 0.08595987373109353}\n",
      "losses : {'ner': 0.02540045509293462}\n",
      "losses : {'ner': 0.007016814447979113}\n",
      "losses : {'ner': 0.07796324311125406}\n",
      "losses : {'ner': 0.5097430888220879}\n",
      "losses : {'ner': 0.005890884539387035}\n",
      "losses : {'ner': 8.208592893052143e-06}\n",
      "losses : {'ner': 0.0008825195149548191}\n",
      "losses : {'ner': 3.133192460109532e-06}\n",
      "losses : {'ner': 0.00012609776739607237}\n",
      "losses : {'ner': 0.0029466021012051874}\n",
      "losses : {'ner': 0.000274822629082245}\n",
      "losses : {'ner': 1.5526551290265886e-05}\n"
     ]
    }
   ],
   "source": [
    "# Begin training by disabling other pipeline components\n",
    "with nlp.disable_pipes(*other_pipes) :\n",
    "    for itn in range(20):\n",
    "        random.shuffle(TRAIN_FOOD_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        #for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        for batch in spacy.util.minibatch(TRAIN_DATA, size=compounding(1.0, 4.0, 1.001)):\n",
    "            for text, annotations in batch:\n",
    "                # create Example\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                # Update the model\n",
    "                nlp.update([example],sgd = optimizer,losses=losses, drop=0.35)\n",
    "        print(\"losses :\",losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41550222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in 'I ate Sushi yesterday. Maggi is a common fast food '\n",
      "Sushi GPE\n",
      "Maggi FOOD\n"
     ]
    }
   ],
   "source": [
    "# Testing the NER\n",
    "\n",
    "test_text = \"I ate Sushi yesterday. Maggi is a common fast food \"\n",
    "\n",
    "doc = nlp(test_text)\n",
    "print(\"Entities in '%s'\" % test_text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d268dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "\n",
    "from pathlib import Path\n",
    "output_dir=Path('/home/robin/assignment Folder/saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e485abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /home/robin/assignment Folder/saved_model\n"
     ]
    }
   ],
   "source": [
    "# Saving the model to the output directory\n",
    "\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()\n",
    "    \n",
    "nlp.meta['name'] = 'my_ner'  # rename model\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c657b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /home/robin/assignment Folder/saved_model\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading from\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir)\n\u001b[1;32m      5\u001b[0m nlp2 \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(output_dir)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m nlp2\u001b[38;5;241m.\u001b[39mget_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmove_names \u001b[38;5;241m==\u001b[39m move_names\n\u001b[1;32m      9\u001b[0m doc2 \u001b[38;5;241m=\u001b[39m nlp2(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Dosa is an extremely famous south Indian dish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m doc2\u001b[38;5;241m.\u001b[39ments:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loading the model from the directory\n",
    "\n",
    "print(\"Loading from\", output_dir)\n",
    "\n",
    "nlp2 = spacy.load(output_dir)\n",
    "\n",
    "assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "\n",
    "doc2 = nlp2(' Dosa is an extremely famous south Indian dish')\n",
    "\n",
    "for ent in doc2.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9938a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOOD Dosa\n",
      "NORP Indian\n",
      "FOOD dish\n"
     ]
    }
   ],
   "source": [
    "nlp2 = spacy.load(output_dir)\n",
    "\n",
    "#assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "\n",
    "doc2 = nlp2(' Dosa is an extremely famous south Indian dish')\n",
    "\n",
    "for ent in doc2.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a2402",
   "metadata": {},
   "source": [
    "# Let's try with another Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4601fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b38adf",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e52f5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a new spacy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# create a DocBin object\n",
    "db = DocBin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd16d1",
   "metadata": {},
   "source": [
    "**In this dataset collected information from differents sites and stored them in a text file. Then annotated the text file with NER Text Annontator and exported the input data as json format.This custom food dataset contains four classes as Food, Place, Country and Person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f13fa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('food.json')\n",
    "\n",
    "TRAIN_DATA = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9173b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': ['FOOD', 'PLACE', 'COUNTRY', 'PERSON'],\n",
       " 'annotations': [['Sushi is a traditional Japanese food made by combining vinegar rice and seafood. There is a type of fermented sushi, known as nare-zushi, but the most typical types of sushi are nigiri-zushi and temaki-zushi.You can find sushi all around Japan, but the sushi from restaurants in high class areas like Ginza or close to fishing ports is especially delicious.',\n",
       "   {'entities': [[0, 5, 'FOOD'],\n",
       "     [23, 31, 'COUNTRY'],\n",
       "     [63, 67, 'FOOD'],\n",
       "     [72, 80, 'FOOD'],\n",
       "     [110, 115, 'FOOD'],\n",
       "     [126, 136, 'FOOD'],\n",
       "     [168, 173, 'FOOD'],\n",
       "     [178, 190, 'FOOD'],\n",
       "     [195, 211, 'FOOD'],\n",
       "     [238, 243, 'COUNTRY'],\n",
       "     [264, 275, 'PLACE'],\n",
       "     [301, 306, 'PLACE'],\n",
       "     [319, 332, 'PLACE']]}],\n",
       "  ['Tempura is a Japanese dish made from seafood, fresh vegetables and other ingredients dipped in a flour and egg batter and fried in oil.',\n",
       "   {'entities': [[0, 7, 'FOOD'],\n",
       "     [13, 21, 'COUNTRY'],\n",
       "     [37, 44, 'FOOD'],\n",
       "     [46, 62, 'FOOD'],\n",
       "     [97, 102, 'FOOD'],\n",
       "     [107, 110, 'FOOD']]}],\n",
       "  ['Ramen is a noodle soup dish which has grown to become incredibly popular and is thought of as a byword for Japanese food. Originally, the soup was made from a chicken bones, but in recent years, pork, beef and seafood also being used in the soup, creating a diverse range of tastes. In addition to the typical salt, soy sauce and miso flavors, you can even find curry flavored ramen now. There is also a type of ramen where the noodles and soup are served separately, known as tsukemen.',\n",
       "   {'entities': [[0, 5, 'FOOD'],\n",
       "     [11, 22, 'FOOD'],\n",
       "     [107, 115, 'COUNTRY'],\n",
       "     [159, 172, 'FOOD'],\n",
       "     [195, 199, 'FOOD'],\n",
       "     [201, 205, 'FOOD'],\n",
       "     [210, 217, 'FOOD'],\n",
       "     [241, 245, 'FOOD'],\n",
       "     [377, 382, 'FOOD'],\n",
       "     [412, 417, 'FOOD'],\n",
       "     [428, 435, 'FOOD'],\n",
       "     [477, 485, 'FOOD']]}],\n",
       "  ['While curry has its origins in India, the curry we eat in Japan is a unique, localized dish based on the curry brought over to Japan from the UK. Made with meat and vegetables (carrots, potatoes, onions, etc.) flavored with curry powder, stewed, and served with rice. Sometimes fried foods, such as pork cutlets, are placed on top of the dish.',\n",
       "   {'entities': [[6, 11, 'FOOD'],\n",
       "     [31, 36, 'COUNTRY'],\n",
       "     [58, 63, 'COUNTRY'],\n",
       "     [127, 132, 'COUNTRY'],\n",
       "     [142, 145, 'COUNTRY'],\n",
       "     [156, 160, 'FOOD'],\n",
       "     [165, 175, 'FOOD'],\n",
       "     [177, 184, 'FOOD'],\n",
       "     [186, 194, 'FOOD'],\n",
       "     [196, 202, 'FOOD'],\n",
       "     [262, 267, 'FOOD'],\n",
       "     [299, 303, 'FOOD'],\n",
       "     [304, 311, 'FOOD']]}],\n",
       "  ['Panta Ilish is a traditional food.It’s a platter of leftover rice soaked in water and served with fried hilsa, achar, and dal.',\n",
       "   {'entities': [[0, 11, 'FOOD'],\n",
       "     [61, 65, 'FOOD'],\n",
       "     [104, 109, 'FOOD'],\n",
       "     [111, 116, 'FOOD'],\n",
       "     [122, 125, 'FOOD']]}],\n",
       "  ['The most popular biryani in Bangladesh is Dhaka Kacchi Biryani.The main ingredients are rice and marinated meat cooked in lots of spices, giving it its special taste. The spices are nutmeg, mace, pepper, cloves, cardamom, cinnamon, bay leaves, coriander, mint, ginger, onion, tomatoes, green chilies, and garlic. It is sometimes served with a boiled egg and salad.',\n",
       "   {'entities': [[17, 24, 'FOOD'],\n",
       "     [28, 38, 'COUNTRY'],\n",
       "     [42, 47, 'PLACE'],\n",
       "     [88, 92, 'FOOD'],\n",
       "     [107, 111, 'FOOD'],\n",
       "     [261, 267, 'FOOD'],\n",
       "     [269, 274, 'FOOD'],\n",
       "     [276, 284, 'FOOD'],\n",
       "     [286, 299, 'FOOD'],\n",
       "     [305, 312, 'FOOD'],\n",
       "     [343, 353, 'FOOD'],\n",
       "     [358, 363, 'FOOD']]}],\n",
       "  ['Jhalmuri is made with Muri, which is puffed rice, and chanachur along with onion, chili, mustard oil, many types of masala, and salad.Bangladeshis call Jhalmuri sellers Mama, which speaks to the relationship between customer and seller.',\n",
       "   {'entities': [[0, 8, 'FOOD'],\n",
       "     [22, 26, 'FOOD'],\n",
       "     [37, 48, 'FOOD'],\n",
       "     [54, 63, 'FOOD'],\n",
       "     [75, 80, 'FOOD'],\n",
       "     [82, 87, 'FOOD'],\n",
       "     [89, 100, 'FOOD'],\n",
       "     [128, 146, 'COUNTRY'],\n",
       "     [169, 173, 'PERSON'],\n",
       "     [216, 224, 'PERSON'],\n",
       "     [229, 235, 'PERSON']]}],\n",
       "  [\"Dosa is an extremely famous south Indian dish.Pizza is a common fast food.Pasta is an italian recipe. China's noodles are very famous. Shrimps are famous in China too Lasagna is another classic of Italy.\",\n",
       "   {'entities': [[0, 4, 'FOOD'],\n",
       "     [28, 40, 'PLACE'],\n",
       "     [69, 79, 'FOOD'],\n",
       "     [86, 93, 'COUNTRY'],\n",
       "     [102, 107, 'COUNTRY'],\n",
       "     [110, 117, 'FOOD'],\n",
       "     [135, 142, 'FOOD'],\n",
       "     [157, 162, 'COUNTRY'],\n",
       "     [167, 174, 'FOOD'],\n",
       "     [197, 202, 'COUNTRY']]}],\n",
       "  [\"Dosa is an extremely famous south Indian dish.Pizza is a common fast food.Pasta is an italian recipe. China's noodles are very famous. Shrimps are famous in China too Lasagna is another classic of Italy.\",\n",
       "   {'entities': [[0, 4, 'FOOD'],\n",
       "     [28, 40, 'PLACE'],\n",
       "     [69, 79, 'FOOD'],\n",
       "     [86, 93, 'COUNTRY'],\n",
       "     [102, 107, 'COUNTRY'],\n",
       "     [110, 117, 'FOOD'],\n",
       "     [135, 142, 'FOOD'],\n",
       "     [157, 162, 'COUNTRY'],\n",
       "     [167, 174, 'FOOD'],\n",
       "     [197, 202, 'COUNTRY']]}]]}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e45720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the JSON data into Spacy NER Format\n",
    "# saved the annotated train data as spacy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8d338a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [00:00<00:00, 38.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for text, annot in tqdm(TRAIN_DATA['annotations']): \n",
    "    doc = nlp.make_doc(text) \n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents \n",
    "    db.add(doc)\n",
    "\n",
    "# save the docbin object\n",
    "db.to_disk(\"./custom_food_training_data.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a4bf526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the model with English language\n",
    "# Using Ner from Spacy pipe line\n",
    "# using efficiency optimize and train the model with cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9551481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-19 15:07:41.463372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 15:07:41.463447: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "! /usr/bin/python3 -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b3fbaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the configured model with training dataset and for validation dataset use the same training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "555a3d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-19 15:12:29.118148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 15:12:29.118188: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-06-19 15:12:32,047] [INFO] Set up nlp object from config\n",
      "[2022-06-19 15:12:32,062] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-06-19 15:12:32,069] [INFO] Created vocabulary\n",
      "[2022-06-19 15:12:32,070] [INFO] Finished initializing nlp object\n",
      "[2022-06-19 15:12:32,357] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     25.67   16.58    9.82   53.26    0.17\n",
      " 32     200        168.02   1633.23  100.00  100.00  100.00    1.00\n",
      " 72     400          0.02      0.04  100.00  100.00  100.00    1.00\n",
      "123     600         11.12      4.90  100.00  100.00  100.00    1.00\n",
      "188     800        103.87     36.41  100.00  100.00  100.00    1.00\n",
      "270    1000         72.24     21.62  100.00  100.00  100.00    1.00\n",
      "370    1200          9.93      2.10  100.00  100.00  100.00    1.00\n",
      "470    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "647    1600         21.28      3.17  100.00  100.00  100.00    1.00\n",
      "847    1800         75.14     11.30  100.00  100.00  100.00    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    }
   ],
   "source": [
    "! /usr/bin/python3 -m spacy train config.cfg --output ./ --paths.train ./custom_food_training_data.spacy --paths.dev ./custom_food_training_data.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde993a",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee1eec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved the model and load the best model for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8e08e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_ner = spacy.load(\"/home/robin/assignment Folder/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99f62106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model with an unseen text using the best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "622ee98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = food_ner('''The Place I love tempura. Having been to Tokyo a few times by now, \n",
    "my favourite go to restaurant for tempura has always been Tempura Tsunahachi in Shinjuku as it is very value for money.\n",
    "On my most recent trip, I decided that it is time to try a more upscale tempura restaurant and Tempura Kondo it shall be. \n",
    "Located in Ginza, the 2-Michelin Star restaurant is very popular among locals.We went for both the Sumire (6,500yen) and Tsubami (8,500yen) lunch menu. \n",
    "For tempura dishes, the former has 2 prawns, 4 vegetables and 3 fishes with rice, miso soup and fruits; the latter has 2 prawns, 5 vegetables and 3 fishes.\n",
    "Tsubaki also comes with Kakiage, a mixture bits of scallop and prawns in batter.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fdea1c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The Place I love \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tempura.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " Having been to Tokyo a few times by now, </br>my favourite go to restaurant for \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tempura\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " has always been \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tempura\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " Tsunahachi in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shinjuku\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COUNTRY</span>\n",
       "</mark>\n",
       " as it is very value for money.</br>On my most recent trip, I decided that it is time to try a more upscale tempura restaurant and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tempura\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " Kondo it shall be. </br>Located in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ginza\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COUNTRY</span>\n",
       "</mark>\n",
       ", the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2-Michelin Star restaurant\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " is very popular among locals.We went for both the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sumire\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6,500yen)\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COUNTRY</span>\n",
       "</mark>\n",
       " and Tsubami (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    8,500yen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ") lunch menu. </br>For tempura dishes, the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    former\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " has 2 \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    prawns\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ", 4 \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    vegetables\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " and 3 fishes with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ", miso soup and fruits; the latter has 2 prawns, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5 vegetables\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " and 3 fishes.</br>Tsubaki also comes with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kakiage\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ", a mixture bits of scallop and prawns in batter.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(test_doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e0210117",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc2 = food_ner('''There are many things in general you can try, from salads to hot dishes, from sweets to soups. But if you want something traditional, cheap and fast – it`s definitely souvlaki. \n",
    "The iconic dish of Greece is a fast food that you usually can find anywhere on the streets, in the bars, in small take-out shops and cafes. You will see souvlaki over the whole country. \n",
    "And if you are lucky enough to be invited to a house party of Greek people – ask for mousaka. It is the best when it`s homemade.\n",
    "\n",
    "It’s hard to speak about Italian food, it’s better to enjoy it. The traditional colors of Italian cuisine – red,\n",
    "green and yellow always create a great mixture of flavor and taste. Usually all the dishes are based on tomato, bread and olive oil.\n",
    "The secret of the cuisine is not in a sophisticated preparation process, it is more in the freshness of the products.\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a95089fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">There are many things in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    general you\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " can try, from \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    salads to\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       " hot dishes, from \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sweets to\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    soups.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       " But if you want something traditional, cheap and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fast – it`s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " definitely souvlaki. </br>The iconic dish of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Greece\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COUNTRY</span>\n",
       "</mark>\n",
       " is a fast \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    food that\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " you usually can find anywhere on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    streets\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ", in the bars, in small take-out shops and cafes. You will see souvlaki over the whole country. </br>And if you are lucky enough to be invited to a house party of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Greek\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COUNTRY</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    people –\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " ask for mousaka. It is the best when it`s homemade.</br></br>It’s \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hard to\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " speak about \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Italian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COUNTRY</span>\n",
       "</mark>\n",
       " food, it’s better to enjoy it. The traditional colors of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Italian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COUNTRY</span>\n",
       "</mark>\n",
       " cuisine – red,</br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    green and\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " yellow always create a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    great mixture\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " of flavor and taste. Usually all the dishes are based on tomato, bread and olive oil.</br>The secret of the cuisine is not in a sophisticated \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    preparation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    process\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ", it is more in the freshness of the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    products.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       "</br></br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(test_doc2, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e3414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7_env",
   "language": "python",
   "name": "python3.7_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
